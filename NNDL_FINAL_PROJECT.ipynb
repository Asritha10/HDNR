{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c750103a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chand\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\chand\\AppData\\Local\\Temp\\ipykernel_8608\\475523638.py\", line 49, in select_file\n",
      "    file_path = tk.filedialog.askopenfilename()\n",
      "AttributeError: module 'tkinter' has no attribute 'filedialog'\n"
     ]
    }
   ],
   "source": [
    "# import tkinter as tk\n",
    "# from PIL import Image, ImageTk\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from keras.models import load_model\n",
    "\n",
    "# # Paths to dataset folders\n",
    "# train_path = \"C:/Users/chand/Desktop/New folder/DeepLearning/Dataset/train\"\n",
    "# test_path = \"C:/Users/chand/Desktop/New folder/DeepLearning/Dataset/test\"\n",
    "\n",
    "# # Load the trained model\n",
    "# model = load_model(\"path/to/your_model.h5\")\n",
    "\n",
    "# # Create the Tkinter window\n",
    "# window = tk.Tk()\n",
    "# window.title(\"Digit Recognition\")\n",
    "# window.geometry(\"400x400\")\n",
    "\n",
    "# # Create a label to display the predicted digit\n",
    "# label = tk.Label(window, text=\"Predicted Digit: \")\n",
    "# label.pack()\n",
    "\n",
    "# # Function to predict the digit\n",
    "# def predict_digit():\n",
    "#     # Convert EPS to grayscale\n",
    "#     img = Image.open(\"temp.eps\")\n",
    "#     img = img.convert(\"L\")\n",
    "    \n",
    "#     # Resize image to match the input size of the model\n",
    "#     img = img.resize((28, 28))\n",
    "    \n",
    "#     # Normalize the image pixel values (if required)\n",
    "#     img = np.array(img) / 255.0\n",
    "    \n",
    "#     # Reshape the image to match the input shape expected by the model\n",
    "#     img = img.reshape(1, 28, 28, 1)\n",
    "    \n",
    "#     # Perform prediction using your deep learning model\n",
    "#     prediction = model.predict(img)\n",
    "    \n",
    "#     # Get the predicted class label\n",
    "#     predicted_class = np.argmax(prediction)\n",
    "    \n",
    "#     # Display the predicted digit\n",
    "#     label.config(text=\"Predicted Digit: \" + str(predicted_class))\n",
    "\n",
    "# # Function to handle file selection\n",
    "# def select_file():\n",
    "#     file_path = tk.filedialog.askopenfilename()\n",
    "    \n",
    "#     # Display the selected image in a Tkinter label\n",
    "#     img = Image.open(file_path)\n",
    "#     img = img.resize((200, 200))\n",
    "#     img = ImageTk.PhotoImage(img)\n",
    "#     image_label.config(image=img)\n",
    "#     image_label.image = img\n",
    "    \n",
    "#     # Save the selected image as EPS file\n",
    "#     img.save(\"temp.eps\")\n",
    "\n",
    "# # Create a button to select an image file\n",
    "# button_select = tk.Button(window, text=\"Select Image\", command=select_file)\n",
    "# button_select.pack()\n",
    "\n",
    "# # Create a label to display the selected image\n",
    "# image_label = tk.Label(window)\n",
    "# image_label.pack()\n",
    "\n",
    "# # Create a button to predict the digit\n",
    "# button_predict = tk.Button(window, text=\"Predict\", command=predict_digit)\n",
    "# button_predict.pack()\n",
    "\n",
    "# # Run the Tkinter event loop\n",
    "# window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aae0d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17000 images belonging to 10 classes.\n",
      "Found 2999 images belonging to 10 classes.\n",
      "Epoch 1/50\n",
      "532/532 [==============================] - 34s 61ms/step - loss: 0.5298 - accuracy: 0.8197 - val_loss: 0.2033 - val_accuracy: 0.9310\n",
      "Epoch 2/50\n",
      "532/532 [==============================] - 32s 59ms/step - loss: 0.2157 - accuracy: 0.9288 - val_loss: 0.1419 - val_accuracy: 0.9533\n",
      "Epoch 3/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.1511 - accuracy: 0.9490 - val_loss: 0.1007 - val_accuracy: 0.9713\n",
      "Epoch 4/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.1250 - accuracy: 0.9584 - val_loss: 0.0713 - val_accuracy: 0.9770\n",
      "Epoch 5/50\n",
      "532/532 [==============================] - 30s 56ms/step - loss: 0.1002 - accuracy: 0.9669 - val_loss: 0.0797 - val_accuracy: 0.9757\n",
      "Epoch 6/50\n",
      "532/532 [==============================] - 30s 56ms/step - loss: 0.0863 - accuracy: 0.9718 - val_loss: 0.0638 - val_accuracy: 0.9800\n",
      "Epoch 7/50\n",
      "532/532 [==============================] - 31s 59ms/step - loss: 0.0764 - accuracy: 0.9741 - val_loss: 0.0611 - val_accuracy: 0.9813\n",
      "Epoch 8/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.0688 - accuracy: 0.9772 - val_loss: 0.0631 - val_accuracy: 0.9797\n",
      "Epoch 9/50\n",
      "532/532 [==============================] - 32s 59ms/step - loss: 0.0556 - accuracy: 0.9815 - val_loss: 0.0659 - val_accuracy: 0.9807\n",
      "Epoch 10/50\n",
      "532/532 [==============================] - 32s 60ms/step - loss: 0.0529 - accuracy: 0.9815 - val_loss: 0.0421 - val_accuracy: 0.9853\n",
      "Epoch 11/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.0495 - accuracy: 0.9853 - val_loss: 0.0529 - val_accuracy: 0.9840\n",
      "Epoch 12/50\n",
      "532/532 [==============================] - 30s 56ms/step - loss: 0.0463 - accuracy: 0.9852 - val_loss: 0.0374 - val_accuracy: 0.9890\n",
      "Epoch 13/50\n",
      "532/532 [==============================] - 28s 53ms/step - loss: 0.0377 - accuracy: 0.9881 - val_loss: 0.0506 - val_accuracy: 0.9833\n",
      "Epoch 14/50\n",
      "532/532 [==============================] - 28s 52ms/step - loss: 0.0401 - accuracy: 0.9867 - val_loss: 0.0592 - val_accuracy: 0.9847\n",
      "Epoch 15/50\n",
      "532/532 [==============================] - 29s 55ms/step - loss: 0.0348 - accuracy: 0.9891 - val_loss: 0.0395 - val_accuracy: 0.9903\n",
      "Epoch 16/50\n",
      "532/532 [==============================] - 32s 60ms/step - loss: 0.0329 - accuracy: 0.9886 - val_loss: 0.0322 - val_accuracy: 0.9897\n",
      "Epoch 17/50\n",
      "532/532 [==============================] - 33s 63ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 0.0408 - val_accuracy: 0.9887\n",
      "Epoch 18/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.0259 - accuracy: 0.9918 - val_loss: 0.0406 - val_accuracy: 0.9867\n",
      "Epoch 19/50\n",
      "532/532 [==============================] - 29s 55ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.0375 - val_accuracy: 0.9867\n",
      "Epoch 20/50\n",
      "532/532 [==============================] - 29s 55ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0424 - val_accuracy: 0.9880\n",
      "Epoch 21/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.0379 - val_accuracy: 0.9890\n",
      "Epoch 22/50\n",
      "532/532 [==============================] - 31s 58ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.0478 - val_accuracy: 0.9880\n",
      "Epoch 23/50\n",
      "532/532 [==============================] - 33s 61ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.0370 - val_accuracy: 0.9893\n",
      "Epoch 24/50\n",
      "532/532 [==============================] - 32s 60ms/step - loss: 0.0216 - accuracy: 0.9919 - val_loss: 0.0385 - val_accuracy: 0.9873\n",
      "Epoch 25/50\n",
      "532/532 [==============================] - 31s 59ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0428 - val_accuracy: 0.9883\n",
      "Epoch 26/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.0186 - accuracy: 0.9934 - val_loss: 0.0452 - val_accuracy: 0.9900\n",
      "Epoch 27/50\n",
      "532/532 [==============================] - 30s 56ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.0403 - val_accuracy: 0.9883\n",
      "Epoch 28/50\n",
      "532/532 [==============================] - 29s 55ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0377 - val_accuracy: 0.9900\n",
      "Epoch 29/50\n",
      "532/532 [==============================] - 29s 55ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.0442 - val_accuracy: 0.9893\n",
      "Epoch 30/50\n",
      "532/532 [==============================] - 29s 55ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0327 - val_accuracy: 0.9913\n",
      "Epoch 31/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.0404 - val_accuracy: 0.9907\n",
      "Epoch 32/50\n",
      "532/532 [==============================] - 31s 58ms/step - loss: 0.0138 - accuracy: 0.9947 - val_loss: 0.0574 - val_accuracy: 0.9863\n",
      "Epoch 33/50\n",
      "532/532 [==============================] - 31s 58ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.0306 - val_accuracy: 0.9923\n",
      "Epoch 34/50\n",
      "532/532 [==============================] - 30s 56ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0362 - val_accuracy: 0.9903\n",
      "Epoch 35/50\n",
      "532/532 [==============================] - 30s 56ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.0304 - val_accuracy: 0.9903\n",
      "Epoch 36/50\n",
      "532/532 [==============================] - 30s 55ms/step - loss: 0.0105 - accuracy: 0.9962 - val_loss: 0.0399 - val_accuracy: 0.9877\n",
      "Epoch 37/50\n",
      "532/532 [==============================] - 29s 55ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.0623 - val_accuracy: 0.9873\n",
      "Epoch 38/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.0345 - val_accuracy: 0.9917\n",
      "Epoch 39/50\n",
      "532/532 [==============================] - 29s 54ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.0550 - val_accuracy: 0.9870\n",
      "Epoch 40/50\n",
      "532/532 [==============================] - 31s 58ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0423 - val_accuracy: 0.9897\n",
      "Epoch 41/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0307 - val_accuracy: 0.9920\n",
      "Epoch 42/50\n",
      "532/532 [==============================] - 32s 60ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0272 - val_accuracy: 0.9937\n",
      "Epoch 43/50\n",
      "532/532 [==============================] - 33s 61ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.0360 - val_accuracy: 0.9920\n",
      "Epoch 44/50\n",
      "532/532 [==============================] - 31s 58ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0351 - val_accuracy: 0.9920\n",
      "Epoch 45/50\n",
      "532/532 [==============================] - 31s 58ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0382 - val_accuracy: 0.9897\n",
      "Epoch 46/50\n",
      "532/532 [==============================] - 31s 58ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0415 - val_accuracy: 0.9900\n",
      "Epoch 47/50\n",
      "532/532 [==============================] - 31s 59ms/step - loss: 0.0133 - accuracy: 0.9950 - val_loss: 0.0470 - val_accuracy: 0.9913\n",
      "Epoch 48/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0429 - val_accuracy: 0.9900\n",
      "Epoch 49/50\n",
      "532/532 [==============================] - 31s 58ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0386 - val_accuracy: 0.9903\n",
      "Epoch 50/50\n",
      "532/532 [==============================] - 30s 57ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0510 - val_accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e207703610>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Paths to dataset folders\n",
    "test_path = r\"C:\\Users\\chand\\Desktop\\New folder\\DeepLearning\\Dataset\\test\"\n",
    "train_path = r\"C:\\Users\\chand\\Desktop\\New folder\\DeepLearning\\Dataset\\train\"\n",
    "\n",
    "# Create a CNN model for digit recognition\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path, target_size=(28, 28), batch_size=32, class_mode='categorical', color_mode='grayscale')\n",
    "test_generator = test_datagen.flow_from_directory(test_path, target_size=(28, 28), batch_size=32, class_mode='categorical', color_mode='grayscale')\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=50, validation_data=test_generator, validation_steps=len(test_generator))\n",
    "\n",
    "\n",
    "\n",
    "# Create the Tkinter window\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8741945",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('digirecog.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# # Load the saved model\n",
    "# model = load_model('path_to_saved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1992ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = tk.Tk()\n",
    "# window.title(\"Digit Recognition\")\n",
    "# window.geometry(\"400x400\")\n",
    "\n",
    "# # Create a label to display the predicted digit\n",
    "# label = tk.Label(window, text=\"Predicted Digit: \")\n",
    "# label.pack()\n",
    "\n",
    "# # Create a drawing canvas\n",
    "# canvas = tk.Canvas(window, width=200, height=200, bg=\"white\")\n",
    "# canvas.pack()\n",
    "\n",
    "# # Function to predict the digit\n",
    "# def predict_digit():\n",
    "#     # Convert the canvas drawing to an image\n",
    "#     ps = canvas.postscript(colormode='gray')\n",
    "#     img = Image.open(io.BytesIO(ps.encode('utf-8')))\n",
    "#     img = img.convert(\"L\")\n",
    "    \n",
    "#     # Resize image to match the input size of the model\n",
    "#     img = img.resize((28, 28))\n",
    "    \n",
    "#     # Normalize the image pixel values\n",
    "#     img = np.array(img) / 255.0\n",
    "    \n",
    "#     # Reshape the image to match the input shape expected by the model\n",
    "#     img = img.reshape(1, 28, 28, 1)\n",
    "    \n",
    "#     # Perform prediction using the deep learning model\n",
    "#     prediction = model.predict(img)\n",
    "    \n",
    "#     # Get the predicted class label\n",
    "#     predicted_class = np.argmax(prediction)\n",
    "    \n",
    "#     # Display the predicted digit\n",
    "#     label.config(text=\"Predicted Digit: \" + str(predicted_class))\n",
    "\n",
    "# # Function to clear the drawing canvas\n",
    "# def clear_canvas():\n",
    "#     canvas.delete(\"all\")\n",
    "\n",
    "# # Create a button to predict the digit\n",
    "# button_predict = tk.Button(window, text=\"Predict\", command=predict_digit)\n",
    "# button_predict.pack()\n",
    "\n",
    "# # Create a button to clear the canvas\n",
    "# button_clear = tk.Button(window, text=\"Clear\", command=clear_canvas)\n",
    "# button_clear.pack()\n",
    "\n",
    "# # Run the Tkinter event loop\n",
    "# window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#     layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation=\"relu\"),\n",
    "#     layers.Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# # Load and preprocess the training data\n",
    "# train_images = []\n",
    "# train_labels = []\n",
    "\n",
    "# for label in range(10):\n",
    "#     folder_path = os.path.join(train_path, str(label))\n",
    "#     images = os.listdir(folder_path)\n",
    "#     for image in images:\n",
    "#         image_path = os.path.join(folder_path, image)\n",
    "#         train_images.append(preprocess_image(image_path))\n",
    "#         train_labels.append(label)\n",
    "\n",
    "# train_images = np.concatenate(train_images)\n",
    "# train_labels = np.array(train_labels)\n",
    "\n",
    "# # Train the model\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Data preprocessing and augmentation\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(train_path, target_size=(28, 28), batch_size=32, class_mode='categorical', color_mode='grayscale')\n",
    "# test_generator = test_datagen.flow_from_directory(test_path, target_size=(28, 28), batch_size=32, class_mode='categorical', color_mode='grayscale')\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=10, validation_data=test_generator, validation_steps=len(test_generator))\n",
    "\n",
    "# model.fit(train_images, train_labels, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e3205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "# model = load_model('path/to/your_model.h5')\n",
    "# digirecog.h5\n",
    "model = load_model('path/to/your_model.h5')\n",
    "# Create the Tkinter window\n",
    "window = tk.Tk()\n",
    "window.title(\"Digit Recognition\")\n",
    "window.geometry(\"400x400\")\n",
    "\n",
    "# Create a label to display the predicted digit\n",
    "label = tk.Label(window, text=\"Predicted Digit: \")\n",
    "label.pack()\n",
    "\n",
    "# Create a drawing canvas\n",
    "canvas_width = 200\n",
    "canvas_height = 200\n",
    "canvas = tk.Canvas(window, width=canvas_width, height=canvas_height, bg=\"white\")\n",
    "canvas.pack()\n",
    "\n",
    "# Create a PIL Image object and a PIL Draw object\n",
    "image = Image.new(\"L\", (canvas_width, canvas_height), 255)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Function to handle mouse movements\n",
    "def on_mouse_move(event):\n",
    "    x, y = event.x, event.y\n",
    "    canvas.create_oval(x, y, x+10, y+10, fill=\"black\")\n",
    "    draw.rectangle([x, y, x+10, y+10], fill=0)\n",
    "\n",
    "# Bind the mouse movement event to the canvas\n",
    "canvas.bind(\"<B1-Motion>\", on_mouse_move)\n",
    "\n",
    "# Function to predict the digit\n",
    "def predict_digit():\n",
    "    # Resize the image to match the input size of the model\n",
    "    resized_image = image.resize((28, 28))\n",
    "    \n",
    "    # Normalize the image pixel values\n",
    "    normalized_image = np.array(resized_image) / 255.0\n",
    "    \n",
    "    # Reshape the image to match the input shape expected by the model\n",
    "    input_image = normalized_image.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    # Perform prediction using the deep learning model\n",
    "    prediction = model.predict(input_image)\n",
    "    \n",
    "    # Get the predicted class label\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    \n",
    "    # Display the predicted digit\n",
    "    label.config(text=\"Predicted Digit: \" + str(predicted_class))\n",
    "\n",
    "# Function to clear the drawing canvas\n",
    "def clear_canvas():\n",
    "    canvas.delete(\"all\")\n",
    "    draw.rectangle([0, 0, canvas_width, canvas_height], fill=255)\n",
    "\n",
    "# Create a button to predict the digit\n",
    "button_predict = tk.Button(window, text=\"Predict\", command=predict_digit)\n",
    "button_predict.pack()\n",
    "\n",
    "# Create a button to clear the canvas\n",
    "button_clear = tk.Button(window, text=\"Clear\", command=clear_canvas)\n",
    "button_clear.pack()\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6c13e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
