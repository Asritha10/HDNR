{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e13124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17000 images belonging to 10 classes.\n",
      "Found 2999 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "266/266 [==============================] - 53s 187ms/step - loss: 1.0530 - accuracy: 0.6555 - val_loss: 0.2596 - val_accuracy: 0.9113\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 37s 139ms/step - loss: 0.4831 - accuracy: 0.8494 - val_loss: 0.1673 - val_accuracy: 0.9453\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 35s 132ms/step - loss: 0.3625 - accuracy: 0.8878 - val_loss: 0.1213 - val_accuracy: 0.9580\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - 35s 133ms/step - loss: 0.2920 - accuracy: 0.9089 - val_loss: 0.0996 - val_accuracy: 0.9680\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - 35s 132ms/step - loss: 0.2561 - accuracy: 0.9201 - val_loss: 0.0874 - val_accuracy: 0.9720\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 0.2272 - accuracy: 0.9296 - val_loss: 0.0630 - val_accuracy: 0.9803\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - 34s 128ms/step - loss: 0.2054 - accuracy: 0.9371 - val_loss: 0.0500 - val_accuracy: 0.9877\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 0.1830 - accuracy: 0.9412 - val_loss: 0.0563 - val_accuracy: 0.9847\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 0.1717 - accuracy: 0.9451 - val_loss: 0.0658 - val_accuracy: 0.9790\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - 34s 128ms/step - loss: 0.1642 - accuracy: 0.9476 - val_loss: 0.0538 - val_accuracy: 0.9823\n",
      "47/47 - 3s - loss: 0.0538 - accuracy: 0.9823 - 3s/epoch - 59ms/step\n",
      "Test accuracy: 0.9823274612426758\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# define the paths to the train and test folders on your desktop\n",
    "train_path = 'C:/Users/chand/Desktop/New folder/DeepLearning/Dataset/train'\n",
    "test_path = 'C:/Users/chand/Desktop/New folder/DeepLearning/Dataset/test'\n",
    "\n",
    "# define image and batch size\n",
    "img_height, img_width = 28, 28\n",
    "batch_size = 64\n",
    "\n",
    "# create ImageDataGenerator objects for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0\n",
    ")\n",
    "\n",
    "# create flow_from_directory generators for train and test datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# define the model architecture\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(img_height, img_width, 1)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(train_generator.num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "# MODEL.summary\n",
    "\n",
    "history = model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
    "\n",
    "# evaluate the model on test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cbafe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 33s 115ms/step\n",
      "47/47 [==============================] - 4s 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chand\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN score: 0.11\n",
      "Decision Tree score: 0.10\n",
      "Random Forest score: 0.12\n",
      "Linear Regression score: -0.00\n",
      "Gradient Boosting score: -0.01\n",
      "XGBoost score: -0.14\n"
     ]
    }
   ],
   "source": [
    "# extract features from the layer before the output of the CNN for both train and test sets\n",
    "train_features = model.predict(train_generator)\n",
    "test_features = model.predict(test_generator)\n",
    "\n",
    "# reshape the feature maps from 4D to 2D for classification\n",
    "train_features = np.reshape(train_features, (train_generator.samples, -1))\n",
    "test_features = np.reshape(test_features, (test_generator.samples, -1))\n",
    "\n",
    "# use the extracted feature vectors for classification using k-NN, decision tree, and random forest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifiers = {\n",
    "    \"k-NN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100)\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(train_features, train_generator.labels)\n",
    "    score = clf.score(test_features, test_generator.labels)\n",
    "    print(\"{} score: {:.2f}\".format(name, score))\n",
    "\n",
    "# use the extracted feature vectors for regression using linear regression, gradient boosted trees, and XGBoost\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "regressors = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"XGBoost\": XGBRegressor()\n",
    "}\n",
    "\n",
    "for name, reg in regressors.items():\n",
    "    reg.fit(train_features, train_generator.labels)\n",
    "    score = reg.score(test_features, test_generator.labels)\n",
    "    print(\"{} score: {:.2f}\".format(name, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc9e85f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "266/266 [==============================] - 45s 159ms/step - loss: 7.8434 - accuracy: 0.0994 - val_loss: 2.4375 - val_accuracy: 0.1000\n",
      "Epoch 2/15\n",
      "266/266 [==============================] - 40s 149ms/step - loss: 2.4371 - accuracy: 0.0984 - val_loss: 2.4359 - val_accuracy: 0.1000\n",
      "Epoch 3/15\n",
      "266/266 [==============================] - 41s 153ms/step - loss: 2.4350 - accuracy: 0.0981 - val_loss: 2.4345 - val_accuracy: 0.1000\n",
      "Epoch 4/15\n",
      "266/266 [==============================] - 41s 155ms/step - loss: 2.4335 - accuracy: 0.0965 - val_loss: 2.4325 - val_accuracy: 0.1000\n",
      "Epoch 5/15\n",
      "266/266 [==============================] - 45s 168ms/step - loss: 2.4339 - accuracy: 0.0954 - val_loss: 2.4342 - val_accuracy: 0.1000\n",
      "Epoch 6/15\n",
      "266/266 [==============================] - 39s 147ms/step - loss: 2.4343 - accuracy: 0.0982 - val_loss: 2.4345 - val_accuracy: 0.1000\n",
      "Epoch 7/15\n",
      "266/266 [==============================] - 39s 148ms/step - loss: 2.4343 - accuracy: 0.0951 - val_loss: 2.4343 - val_accuracy: 0.1000\n",
      "Epoch 8/15\n",
      "266/266 [==============================] - 40s 150ms/step - loss: 2.4355 - accuracy: 0.0992 - val_loss: 2.4362 - val_accuracy: 0.0997\n",
      "Epoch 9/15\n",
      "266/266 [==============================] - 40s 148ms/step - loss: 2.4374 - accuracy: 0.0978 - val_loss: 2.4381 - val_accuracy: 0.0997\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# define the model architecture with regularization and dropout layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(img_height, img_width, 1)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\", kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(train_generator.num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# define early stopping callback\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# train the model with data augmentation and early stopping\n",
    "history = model.fit(train_generator, epochs=15, validation_data=test_generator, callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0ea1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
