{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700d8a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17000 images belonging to 10 classes.\n",
      "Found 2999 images belonging to 10 classes.\n",
      "Epoch 1/5\n",
      "266/266 [==============================] - 44s 137ms/step - loss: 1.2202 - accuracy: 0.6055 - val_loss: 0.3588 - val_accuracy: 0.9160\n",
      "Epoch 2/5\n",
      "266/266 [==============================] - 34s 130ms/step - loss: 0.5430 - accuracy: 0.8335 - val_loss: 0.2006 - val_accuracy: 0.9406\n",
      "Epoch 3/5\n",
      "266/266 [==============================] - 35s 130ms/step - loss: 0.3633 - accuracy: 0.8870 - val_loss: 0.1220 - val_accuracy: 0.9733\n",
      "Epoch 4/5\n",
      "266/266 [==============================] - 35s 130ms/step - loss: 0.2860 - accuracy: 0.9126 - val_loss: 0.0925 - val_accuracy: 0.9753\n",
      "Epoch 5/5\n",
      "266/266 [==============================] - 35s 130ms/step - loss: 0.2443 - accuracy: 0.9236 - val_loss: 0.0704 - val_accuracy: 0.9857\n",
      "47/47 - 2s - loss: 0.0704 - accuracy: 0.9857 - 2s/epoch - 52ms/step\n",
      "Test accuracy: 0.9856618642807007\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# define the paths to the train and test folders on your desktop\n",
    "train_path = 'C:/Users/chand/Desktop/New folder/DeepLearning/Dataset/train'\n",
    "test_path = 'C:/Users/chand/Desktop/New folder/DeepLearning/Dataset/test'\n",
    "\n",
    "# define image and batch size\n",
    "img_height, img_width = 28, 28\n",
    "batch_size = 64\n",
    "\n",
    "# create ImageDataGenerator objects for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0\n",
    ")\n",
    "\n",
    "# create flow_from_directory generators for train and test datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# define the CNN architecture\n",
    "cnn = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(img_height, img_width, 1)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define the LSTM architecture\n",
    "rnn = keras.Sequential(\n",
    "    [\n",
    "        layers.Reshape((1, 128)),\n",
    "        layers.LSTM(64),\n",
    "        layers.Dense(train_generator.num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# combine the CNN and RNN architectures\n",
    "model = keras.Model(inputs=cnn.input, outputs=rnn(cnn.output))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(train_generator, epochs=5, validation_data=test_generator)\n",
    "\n",
    "# evaluate the model on test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeab0ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 2s - loss: 0.0704 - accuracy: 0.9857 - 2s/epoch - 51ms/step\n",
      "Test accuracy (RNN): 0.9856618642807007\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print(\"Test accuracy (RNN):\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b38eb799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17000 images belonging to 10 classes.\n",
      "Found 2999 images belonging to 10 classes.\n",
      "Epoch 1/5\n",
      "266/266 [==============================] - 36s 128ms/step - loss: 1.0929 - accuracy: 0.6419 - val_loss: 0.2900 - val_accuracy: 0.9010\n",
      "Epoch 2/5\n",
      "266/266 [==============================] - 35s 130ms/step - loss: 0.5141 - accuracy: 0.8359 - val_loss: 0.1381 - val_accuracy: 0.9637\n",
      "Epoch 3/5\n",
      "266/266 [==============================] - 34s 129ms/step - loss: 0.3703 - accuracy: 0.8838 - val_loss: 0.1098 - val_accuracy: 0.9677\n",
      "Epoch 4/5\n",
      "266/266 [==============================] - 34s 129ms/step - loss: 0.3147 - accuracy: 0.9039 - val_loss: 0.0888 - val_accuracy: 0.9737\n",
      "Epoch 5/5\n",
      "266/266 [==============================] - 32s 122ms/step - loss: 0.2667 - accuracy: 0.9158 - val_loss: 0.0778 - val_accuracy: 0.9763\n",
      "Epoch 1/5\n",
      "266/266 [==============================] - 46s 140ms/step - loss: 1.4147 - accuracy: 0.5056 - val_loss: 0.5257 - val_accuracy: 0.8306\n",
      "Epoch 2/5\n",
      "266/266 [==============================] - 35s 130ms/step - loss: 0.7642 - accuracy: 0.7330 - val_loss: 0.3189 - val_accuracy: 0.8803\n",
      "Epoch 3/5\n",
      "266/266 [==============================] - 37s 139ms/step - loss: 0.5574 - accuracy: 0.8082 - val_loss: 0.2318 - val_accuracy: 0.9166\n",
      "Epoch 4/5\n",
      "266/266 [==============================] - 33s 123ms/step - loss: 0.4357 - accuracy: 0.8543 - val_loss: 0.1582 - val_accuracy: 0.9490\n",
      "Epoch 5/5\n",
      "266/266 [==============================] - 31s 118ms/step - loss: 0.3718 - accuracy: 0.8769 - val_loss: 0.1396 - val_accuracy: 0.9507\n",
      "47/47 - 2s - loss: 0.0778 - accuracy: 0.9763 - 2s/epoch - 45ms/step\n",
      "47/47 - 2s - loss: 0.1396 - accuracy: 0.9507 - 2s/epoch - 48ms/step\n",
      "CNN Test accuracy: 0.9763254523277283\n",
      "RNN Test accuracy: 0.9506502151489258\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths to the train and test folders\n",
    "train_path = 'C:/Users/chand/Desktop/New folder/DeepLearning/Dataset/train'\n",
    "test_path = 'C:/Users/chand/Desktop/New folder/DeepLearning/Dataset/test'\n",
    "\n",
    "# Define image and batch size\n",
    "img_height, img_width = 28, 28\n",
    "batch_size = 64\n",
    "\n",
    "# Create ImageDataGenerator objects for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0\n",
    ")\n",
    "\n",
    "# Create flow_from_directory generators for train and test datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Define the CNN architecture\n",
    "cnn = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(img_height, img_width, 1)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(train_generator.num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the LSTM architecture\n",
    "rnn = keras.Sequential(\n",
    "    [\n",
    "        layers.Reshape((img_height, img_width)),\n",
    "        layers.Bidirectional(layers.LSTM(64)),\n",
    "        layers.Dense(train_generator.num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the models\n",
    "cnn.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "rnn.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the CNN\n",
    "cnn_history = cnn.fit(train_generator, epochs=5, validation_data=test_generator)\n",
    "\n",
    "# Train the RNN\n",
    "rnn_history = rnn.fit(train_generator, epochs=5, validation_data=test_generator)\n",
    "\n",
    "# Evaluate the models on test set\n",
    "cnn_test_loss, cnn_test_acc = cnn.evaluate(test_generator, verbose=2)\n",
    "rnn_test_loss, rnn_test_acc = rnn.evaluate(test_generator, verbose=2)\n",
    "\n",
    "print(\"CNN Test accuracy:\", cnn_test_acc)\n",
    "print(\"RNN Test accuracy:\", rnn_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603baa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
